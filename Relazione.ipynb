{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StackOverflow Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si è voluto formulare uno studio relativo al dataset di StackOverflow disponibile su Kaggle al seguente indirizzo: \n",
    "    https://www.kaggle.com/stackoverflow/stackoverflow\n",
    "    \n",
    "Stack Overflow è un sito di domande e risposte relative al mondo della programmazione. E' nato nel 2008 e si sostanzia in una piattaforma a partecipazione attiva in quanto ogni domanda e ogni risposta è valutata dalla community stessa, il che porta a perdere o guadagnare reputazione in base al proprio contributo, risultando in diversi privilegi.\n",
    "Al 2019, il conteggio degli utenti supera i 16 milioni.\n",
    "    \n",
    "Il dataset comprende i dati della piattaforma dal 2008 ad oggi, risultante in più di 600 milioni di osservazioni distribuite su 16 tabelle, ognuna delle quali costituita da minimo 15 colonne. \n",
    "Il dataset fornisce diversi tipi di dati: dati relativi agli utenti, alle domande e risposte date dagli stessi, i post pubblicati e la totalità dei tag utilizzati sino ad oggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google BigQuery\n",
    "Essendo un datasert particolarmente ampio e corposo l'accesso agli stessi dati è stato posibile grazie ad un servizio fornito da Google chiamato BigQuery.\n",
    "\n",
    "BigQuery è un servizio RESTful erogato come PaaS (Platform as a Service) che offre accesso a grandi moli di dati, andando a sgravare la responsabilità di computazione dei dati in questione nei confronti del client.\n",
    "Al fine di consultare i dati desiderati, BigQuery permette l'utilizzo di Standard SQL per formulare query che verranno eseguite sul cloud, utilizzando la potenza computazionale offerta dalle macchine Google, risultando in query anche piuttosto complesse venire eseguite con una latenza relativamente minima.\n",
    "\n",
    "Nel nostro caso particolare l'utilizzo del servizio si è limitato alla richiesta di specifiche query al fine di ottenere i dati desiderati, ma lo stesso offre diverse feature sintetizzabili come segue:\n",
    "- **Gestione dei dati** => possibilità di creare, eliminare strutture quali tabelle e views. E' possibile importare i dati in formato CSV, Parquet, Avro e JSON dalla piattaforma Google Storage.\n",
    "- **Query** => query espresse in Standard SQL rendendo possibile l'accesso a dati desiderati.\n",
    "- **Access Control** => BigQuery non permette di effettuare richieste di alcun tipo se non ad entità autenticate.\n",
    "- **Machine Learning** => infine il serizio rende disponibile la creazione ed esecuzione di modelli di Machine Learning tramite query SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "Come accennato in precedenza, l'uso di BigQuery involve l'utilizzo di un linguaggio di query come SQL, permettendo così l'accesso a grandi moli di dati come nel nostro caso. Quindi prima dell'effettiva fase di analisi, ci si è concentrati sul processo di raccolta dei dati e della loro importazione in un formato utilizabile, Pandas DataFrame nel nostro caso.\n",
    "Di seguito verranno esposte le funzionalità di maggior importanza.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autenticazione\n",
    "Per utilizzare il servizio BigQuery è necessario anzitutto essere autenticati e disporre di un account sulla piattaforma di Google Cloud. Di seguito si necessita la creazione di una chiave di autenticazione, in formato JSON nel nostro caso, disponibile al download una volta creato l'account Google Cloud e da includere nel progetto per essere utilizzata come segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery as bq\n",
    "from google.cloud import bigquery_storage as bq_storage #import external packages\n",
    "\n",
    "client = bq.Client.from_service_account_json(\"key.json\")\n",
    "storage_client = bq_storage.BigQueryReadClient.from_service_account_json(\"key.json\")\n",
    "\n",
    "bq_dataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n",
    "bq_dataset = client.get_dataset(bq_dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si denota, viene anzitutto creata un' istanza di client dalla chiave in formato JSON fornita e instaurata una connessione bidirezionale, in grado di ricevere ed inviare dati al server remoto su cui si effettuano le richieste. \n",
    "Inoltre è necessario creare una referenza al dataset desiderato attraverso il nome e al progetto di cui fa parte e da essa ottenere l'effettiva istanza del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interrogazione e conversione a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' possibile dunque scrivere la query ed eventualmente fornire un limite di risultati desiderati, in quanto si ricorda come BigQuery offre solamente 1 TB mensile di dati scaricabili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000000 #--> 1 MLN\n",
    "\n",
    "query = '''\n",
    "    SELECT RAND() as r, tags, creation_date FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "    WHERE DATETIME(creation_date) < DATETIME(2020, 3,30,0,0,0)\n",
    "    ORDER BY r\n",
    "    LIMIT ''' + str(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizzando la funzione result() si effettua la richiesta secondo la query specificata ed infine attraverso la funzione to_dataframe() è possibile convertire i risultati ottenuti in un DataFrame Pandas pronto per una successiva analisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_question = (\n",
    "    client.query(query).result()\n",
    "    .to_dataframe(bqstorage_client=storage_client)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvare e leggere un DataFrame\n",
    "\n",
    "Trovandosi a lavorari con grandi quantità di dati sarebbe stato alquanto scomodo effettuare una query ogni volta senza mai persistere i dati ottenuti, anche e soprattutto per il vincolo di quantità imposto da BigQuery. \n",
    "Si è deciso dunque di salvare ogni DataFrame ottenuto dopo aver testato il corretto funzionamento di ogni query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_question.to_csv('tags_dataframe.csv') #si salva il DataFrame in formato CSV nella cartella di progetto corrente\n",
    "\n",
    "read_df = pd.read_csv('tags_dataframe.csv') #si legge il file e si ottiene il DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "L'intera analisi è basata su domande di fondo che ci siamo posti inizialmente.\n",
    "Quest'ultime avevano l'obiettivo di far chiarezza su un particolare aspetto del dataset e allo stesso tempo portare un'analisi esplorativa di aspetti da noi ritenuti interessanti. \n",
    "Principalmente ci si è concentrati su analisi relative agli utenti e l'influenza che essi hanno sull'environment \"sociale\" della piattaforma, basandosi sulla reputazione e al contributo di ogni utente evidenziabile in domande e risposte date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine si è voluto dare spazio a degli off topic relativi ad interessi personali come i framework per lo sviluppo web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi Utente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quanti utenti contribuiscono alla comunità ? \n",
    "\n",
    "La prima domanda che è stata pensata riguarda la società di StackOverflow.\n",
    "Essendo che la maggior parte degli utenti utilizza il network per fini personali, senza quindi rispondere alle domande di altri, ci si è chiesti come possa la società rimanere in piedi e continuare a fornire risposte a chi ne necessita.\n",
    "\n",
    "Per rispondere a questa domanda, si sono suddivisi gli utenti in 4 categorie, in base al numero e al tipo di post che ogni utente ha pubblicato su StackOverflow.\n",
    "\n",
    "Abbiamo quindi suddiviso gli utenti in 4 categorie:\n",
    "\n",
    "| Category | Description  |\n",
    "|------|------|\n",
    "|   Askers  | Utenti che hanno pubblicato almeno una domanda e nessuna risposta|\n",
    "|Answerers| Utenti che hanno pubblicato almeno una risposta e nessuna domanda|\n",
    "|Both| Utenti che hanno pubblicato sia risposte che domande|\n",
    "|Lazy| Utenti che non hanno pubblicato né domande né risposte|\n",
    "\n",
    "#### Gathering\n",
    "Per questo tipo di analisi non è stato necessario creare alcun dataframe, bensì è stato utilizzato solo il servizio di BigQuery per osservare il conteggio degli utenti appartenenti a ciascuna categoria.\n",
    "Per ottenere questo numero, sono state eseguite le seguenti sottostanti.\n",
    "\n",
    "Si può notare come a posteri dell'esecuzione di ciascuna query, il risultato viene convertito in un dataframe tramite BigQuery Storage per poi selezionare il valore contenuto nella prima cella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_query = '''\n",
    "    select count(distinct questions.owner_user_id) as askers\n",
    "    from bigquery-public-data.stackoverflow.posts_questions as questions\n",
    "    left join `bigquery-public-data.stackoverflow.posts_answers` as answers\n",
    "    on answers.owner_user_id = questions.owner_user_id\n",
    "    where answers.owner_user_id is null\n",
    "    '''\n",
    "\n",
    "answer_query = '''\n",
    "    select count(distinct answers.owner_user_id) as responder\n",
    "    from bigquery-public-data.stackoverflow.posts_answers as answers\n",
    "    left join bigquery-public-data.stackoverflow.posts_questions as questions\n",
    "    on answers.owner_user_id = questions.owner_user_id\n",
    "    where questions.owner_user_id is null\n",
    "    '''\n",
    "\n",
    "both_query = '''\n",
    "    select count(distinct questions.owner_user_id) as responder\n",
    "    from bigquery-public-data.stackoverflow.posts_answers as answers\n",
    "    inner join bigquery-public-data.stackoverflow.posts_questions as questions\n",
    "    on answers.owner_user_id = questions.owner_user_id\n",
    "    '''\n",
    "\n",
    "lazy_query = '''\n",
    "    with posts as (\n",
    "        select distinct owner_user_id from bigquery-public-data.stackoverflow.posts_answers\n",
    "        union all\n",
    "        select distinct owner_user_id from bigquery-public-data.stackoverflow.posts_questions\n",
    "    )\n",
    "    select count(user.id) as lazy\n",
    "    from bigquery-public-data.stackoverflow.users as user \n",
    "    left join posts\n",
    "    on posts.owner_user_id = user.id\n",
    "    where posts.owner_user_id is null\n",
    "    '''\n",
    "\n",
    "askers = (\n",
    "    client.query(quest_query)\n",
    "    .result()\n",
    "    .to_dataframe(bqstorage_client=storage_client)\n",
    "    .iat[0,0]\n",
    ")\n",
    "\n",
    "responder = (\n",
    "    client.query(answer_query)\n",
    "    .result()\n",
    "    .to_dataframe(bqstorage_client=storage_client)\n",
    "    .iat[0,0]\n",
    ")\n",
    "\n",
    "lazy = (\n",
    "    client.query(lazy_query)\n",
    "    .result()\n",
    "    .to_dataframe(bqstorage_client=storage_client)\n",
    "    .iat[0,0]\n",
    ")\n",
    "\n",
    "both = (\n",
    "    client.query(both_query)\n",
    "    .result()\n",
    "    .to_dataframe(bqstorage_client=storage_client)\n",
    "    .iat[0,0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E' meritocratica la società di StackOverflow ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguendo le considerazioni fatte in precedenza relativamente al contributo medio di ogni singolo utente e come è bilanciato il sostentamento della piattoforma in base alla loro attività (numero di domande e risposte), si è voluto approfondire ulteriormente la questione in ambito utenti provando inizialmente a suddividere ogni utente in diverse categorie di reputazione. \n",
    "La reputazione su StackOverflow consiste in un numero che meglio dovrebbe indicare quanto la community si fida di un utente e delle sue risposte. Guadagnando reputazione si dispongono particolari privilegi, vedi\n",
    "moderator tools https://meta.stackexchange.com/help/privileges/moderator-tools.\n",
    "La reputazione è guadagnata rispondendo in maniera utile a determinate domande e, dall'altra parte, ponendo domande interessanti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azioni principali (+):\n",
    "- **Domanda contrassegnata come utile** => +10\n",
    "- **Risposta contrassegnata come utile** => +10\n",
    "- **Risposta contrassegnata come accettata** => +15 (+2 all'utente che la accetta)\n",
    "- **Modifica contrassegnata come accettata** => +2 (max: +1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azioni principali (-):\n",
    "- **Domanda contrassegnata come non utile** => -2\n",
    "- **Risposta contrassegnata come non utile** => -2\n",
    "- **Risposta contrassegnata come non utile da te** => -1\n",
    "- **Uno dei post riceve 6 segnalazioni di spam o insulti** => -600\n",
    "\n",
    "E' possibile guadagnare al massimo 200 punti reputazione al giorno.\n",
    "Si lasciano qui di seguito ulteriori informazioni sull'assegnazione del punteggio reputazione https://stackoverflow.com/help/bounty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito a questi ragionamenti sorge spontaneo domandarsi come è a sua volta bilanciato il contributo di ogni macrocategoria di reputazione in quanto a domande e risposte date e se questo dato rispecchia la reputazione stessa, con utenti con un'alta reputazione e molte risposte date e, viceversa, utenti con bassa reputazione e parecchie domande accompagnate da poche risposte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al fine si necessitano dati relativo al numero di utenti, il numero di domande e risposte ognuno e il relativo punteggio di reputazione "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gathering\n",
    "Si è scritta una query che permettesse il raccoglimento dei sopracitati dati ed essendo i dati relativi ad utenti, domande e risposte contenuti in tabelle differenti, si è fatto uso di un JOIN.\n",
    "Ogni utente però poteva anche non avere dato nè domande nè risposte durante la sua vita su StackOverflow, dunque si è dovuto utilizzare un JOIN che tenesse conto di questo particolare, un LEFT JOIN.\n",
    "Infatti quest'ultimo ritorna tutte le entries dalla tabella di sinistra e solamente i relativi match nella tabella di destra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_view = '''\n",
    "                SELECT id AS user_id, reputation, asked, answered\n",
    "                        FROM `bigquery-public-data.stackoverflow.users` users\n",
    "                        LEFT JOIN(\n",
    "                            SELECT owner_user_id AS user_id, COUNT(*) AS asked\n",
    "                            FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "                            GROUP BY user_id\n",
    "                        ) questions ON users.id = questions.user_id\n",
    "                        LEFT JOIN(\n",
    "                            SELECT owner_user_id AS user_id, COUNT(*) AS answered\n",
    "                            FROM `bigquery-public-data.stackoverflow.posts_answers`\n",
    "                            GROUP BY user_id\n",
    "                        ) answers ON users.id = answers.user_id\n",
    "                limit '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ottiene dunque un dataset con tante entries quante gli utenti, ognuna con il relativo conteggio di domande e risposte. Il nostro obiettivo però è ottenere dei dati raggruppati per reputazione con il conteggio di domande e risposta a sua volta raggruppato per reputazione.\n",
    "Volendo sfruttare quindi la potenza di BigQuery, o per semplice comodità, si è riutilizzata la query come subquery per una nuova comprensiva dell'aggregazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reputation</th>\n",
       "      <th>users</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2820</td>\n",
       "      <td>31</td>\n",
       "      <td>469.0</td>\n",
       "      <td>1787.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1219</td>\n",
       "      <td>138</td>\n",
       "      <td>2969.0</td>\n",
       "      <td>2895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181</td>\n",
       "      <td>5467</td>\n",
       "      <td>26025.0</td>\n",
       "      <td>20314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1696</td>\n",
       "      <td>43</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2885</td>\n",
       "      <td>30</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>1011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25291</th>\n",
       "      <td>3915</td>\n",
       "      <td>16</td>\n",
       "      <td>304.0</td>\n",
       "      <td>1025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25292</th>\n",
       "      <td>4466</td>\n",
       "      <td>16</td>\n",
       "      <td>414.0</td>\n",
       "      <td>818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25293</th>\n",
       "      <td>3940</td>\n",
       "      <td>16</td>\n",
       "      <td>569.0</td>\n",
       "      <td>1282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25294</th>\n",
       "      <td>4440</td>\n",
       "      <td>16</td>\n",
       "      <td>947.0</td>\n",
       "      <td>936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25295</th>\n",
       "      <td>3517</td>\n",
       "      <td>16</td>\n",
       "      <td>302.0</td>\n",
       "      <td>912.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25296 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reputation  users  questions  answers\n",
       "0            2820     31      469.0   1787.0\n",
       "1            1219    138     2969.0   2895.0\n",
       "2             181   5467    26025.0  20314.0\n",
       "3            1696     43      837.0   1448.0\n",
       "4            2885     30     1221.0   1011.0\n",
       "...           ...    ...        ...      ...\n",
       "25291        3915     16      304.0   1025.0\n",
       "25292        4466     16      414.0    818.0\n",
       "25293        3940     16      569.0   1282.0\n",
       "25294        4440     16      947.0    936.0\n",
       "25295        3517     16      302.0    912.0\n",
       "\n",
       "[25296 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_query = '''\n",
    "            SELECT\n",
    "                reputation AS reputation,\n",
    "                COUNT(*) AS users,\n",
    "                SUM(asked) AS questions,\n",
    "                SUM(answered) AS answers\n",
    "            FROM(\n",
    "                SELECT id AS user_id, reputation, asked, answered\n",
    "                            FROM `bigquery-public-data.stackoverflow.users` users\n",
    "                            LEFT JOIN(\n",
    "                                SELECT owner_user_id AS user_id, COUNT(*) AS asked\n",
    "                                FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "                                GROUP BY user_id\n",
    "                            ) questions ON users.id = questions.user_id\n",
    "                            LEFT JOIN(\n",
    "                                SELECT owner_user_id AS user_id, COUNT(*) AS answered\n",
    "                                FROM `bigquery-public-data.stackoverflow.posts_answers`\n",
    "                                GROUP BY user_id\n",
    "                            ) answers ON users.id = answers.user_id\n",
    "            )\n",
    " group by reputation\n",
    " '''\n",
    "\n",
    "aggregate = (\n",
    "    client.query(aggregate_query)\n",
    "    .result()\n",
    "    .to_dataframe(bqstorage_client=storage_client)\n",
    ")\n",
    "\n",
    "aggregate.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset ottenuto non rispecchia ancora i nostri bisogni; come si vede ora i dati sono raggruppati sì per reputazione ma per ogni singolo valori\n",
    "edi essa. Si necessita un ulteriore raggruppamento basato su range di reputazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota particolare è il fatto che avendo utilizzato un LEFT JOIN eventuali dati mancanti dalle tabelle di destra (in questo caso domande e risposte) vengono riportate come NaN. Per ovviare questo comportamento si sostituisce ogni NaN con 0, attraverso la funzione .fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per comodità da ora in poi si utilizzeranno funzionalità presenti in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reputationToCategory(x):\n",
    "    if(x >= 1 and x <= 100):\n",
    "        return \"Usurpers\"\n",
    "    elif(x > 100 and x <= 1000):\n",
    "        return \"Slaves\"\n",
    "    elif(x > 1000 and x <= 10000):\n",
    "        return \"Lords\"\n",
    "    elif(x > 10000 and x <= 100000):\n",
    "        return \"Grandmasters\"\n",
    "    else: return \"Gods\"\n",
    "        \n",
    "    \n",
    "\n",
    "aggregate['reputation'] = aggregate['reputation'].map(reputationToCategory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ogni punteggio di categoria è convertito nella relativa classe (nomi simpatici per evidenziare ulteriormente il ruolo). Si sono scelte range di categoria ascendenti per rispecchiare meglio la distribuzione di reputazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine non resta che utilizzare la funzione di raggruppamento di Pandas per ottenere il DataFrame desiderato, con i dati raggruppati per range di reputazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reputation_df = aggregate.groupby(['reputation']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dati ottenuti rappresentano la totalità dei dati relativi presenti nel dataset, quindi un semplice conteggio. Al fine di visualizzare quanto ottenuto in maniera grafica si è voluto normalizzare i dati rispetto al totale e fornirli in forma percentuale.\n",
    "Si fa uso delle seguenti funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeUsersCount(x):\n",
    "    totalUsers = df_plot['users'].sum()\n",
    "    return (x * 100) / totalUsers\n",
    "def normalizeQuestionsCount(x):\n",
    "    totalQuestions = df_plot['questions'].sum()\n",
    "    return (x * 100) / totalQuestions\n",
    "def normalizeAnswersCount(x):\n",
    "    totalAnswers = df_plot['answers'].sum()\n",
    "    return (x * 100) / totalAnswers\n",
    "\n",
    "df_plot['users'] = df_plot['users'].map(normalizeUsersCount)\n",
    "df_plot['questions'] = df_plot['questions'].map(normalizeQuestionsCount)\n",
    "df_plot['answers'] = df_plot['answers'].map(normalizeAnswersCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine non resta che plottare i grafici e visualizzare i dati, confrontandoli con le aspettative iniziali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'reputation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'reputation'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-49c452ee20f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reputation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"users\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m fig.update_layout(title={\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2891\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2893\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'reputation'"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=df_plot[\"reputation\"], values=df_plot[\"users\"], pull=[0.3, 0.2, 0.15, 0.1, 0])])\n",
    "fig.update_layout(title={\n",
    "        \"x\":0.5,\n",
    "        \"y\":0.95,\n",
    "        \"text\":\"Users of Stack Overflow based on reputation categories\",\n",
    "        \"xanchor\":\"center\",\n",
    "        \"yanchor\":\"top\"\n",
    "    })\n",
    "fig.update_traces(marker=dict(colors=[\"#d5d5d5\", \"#223943\", \"#1438de\", \"#c4a15a\", \"#007668\"]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_df = df_plot.iloc[::-1]\n",
    "\n",
    "colors_answer = [\"#223943\"] * 5\n",
    "colors_question = [\"#c4a15a\"] * 5\n",
    "\n",
    "bar = go.Figure(data=[\n",
    "    go.Bar(name='Questions', x=bar_df[\"reputation\"], y=bar_df[\"questions\"], marker_color=colors_question),\n",
    "    go.Bar(name='Answers', x=bar_df[\"reputation\"], y=bar_df[\"answers\"], marker_color=colors_answer)\n",
    "])\n",
    "\n",
    "\n",
    "bar.update_layout(barmode='group', xaxis={'categoryorder':'trace'}, title='Percentage of questions and answers per reputation category',\n",
    "    xaxis_tickfont_size=14,\n",
    "    yaxis=dict(\n",
    "        title='Percent of Questions/Anwers',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,\n",
    "    ), bargroupgap=0.05)\n",
    "\n",
    "bar.update_yaxes(tickprefix=\"%\", showgrid=True)\n",
    "bar.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dal primo grafico si denota che la stragrande maggioranza di utenti presenti su StackOverflow(>90%) presenta un basso grado di reputazione (1 -100) a fronte del rimanente 8% circa di utenti su cui sono ripartite le rimanenti.\n",
    "Analogamente alla prima analisi, si nota sempre come la società di StackOverflow sia propriamente di stampo oligarchico, in cui la vera forza trascinatrice (l'arte della risposta) della piattaforma risiede nelle mani di un gruppo di pochi, che, però, a quanto pare, risulta molto attivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infatti si constata come il 90% delle domande sia concentrato nelle prime tre categorie di reputazione, dato dal fatto che molto probabilmente utenti con maggiore reputazione solitamente sono utenti autorevoli e consapevoli, con un ridotto bisogno di porre domande. Analogamente il 70% delle risposte date appartiene alle 3 categorie con reputazione più alta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effettivamente, anche dopo aver compreso le prime analisi, ci si aspettava un risultato di questo tipo dove il potere di risposta propende verso categorie con maggiore reputazione, in una società che per la sua quasi interezza è rappresentata da utenti non contribuenti che effettuano relativamente poche risposte a fronte delle innumerevoli domande poste. L'istogramma infatti mostra una netta inversione di marcia; si nota inoltre come il bilanciamento quasi perfetto tra percentuale di domande fatte e risposte date si ha nella terza categoria (1000 - 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Off Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le vecchie tecnologie stanno per essere dimenticate ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
